{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "import torchvision\r\n",
    "import torch\r\n",
    "from torch.utils.data import DataLoader as DataLoader\r\n",
    "import argparse\r\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_names = [\r\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\r\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\r\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\r\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\r\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\r\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\r\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\r\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\r\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\r\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\r\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\r\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\r\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will help us create a different color for each class\r\n",
    "COLORS = np.random.uniform(0, 255, size=(len(coco_names), 3))\r\n",
    "\r\n",
    "# define the torchvision image transforms\r\n",
    "transform = transforms.Compose([\r\n",
    "    transforms.ToTensor(),\r\n",
    "])\r\n",
    "\r\n",
    "def predict(image, model, device, detection_threshold):\r\n",
    "    # transform the image to tensor\r\n",
    "    image = transform(image).to(device)\r\n",
    "    image = image.unsqueeze(0) # add a batch dimension\r\n",
    "    outputs = model(image) # get the predictions on the image\r\n",
    "    # print the results individually\r\n",
    "    # print(f\"BOXES: {outputs[0]['boxes']}\")\r\n",
    "    # print(f\"LABELS: {outputs[0]['labels']}\")\r\n",
    "    # print(f\"SCORES: {outputs[0]['scores']}\")\r\n",
    "    # get all the predicited class names\r\n",
    "    pred_classes = [coco_names[i] for i in outputs[0]['labels'].cpu().numpy()]\r\n",
    "    # get score for all the predicted objects\r\n",
    "    pred_scores = outputs[0]['scores'].detach().cpu().numpy()\r\n",
    "    # get all the predicted bounding boxes\r\n",
    "    pred_bboxes = outputs[0]['boxes'].detach().cpu().numpy()\r\n",
    "    # get boxes above the threshold score\r\n",
    "    boxes = pred_bboxes[pred_scores >= detection_threshold].astype(np.int32)\r\n",
    "    return boxes, pred_classes, outputs[0]['labels']\r\n",
    "\r\n",
    "def draw_boxes(boxes, classes, labels, image):\r\n",
    "    # read the image with OpenCV\r\n",
    "    image = cv2.cvtColor(np.asarray(image), cv2.COLOR_BGR2RGB)\r\n",
    "    for i, box in enumerate(boxes):\r\n",
    "        color = COLORS[labels[i]]\r\n",
    "        cv2.rectangle(\r\n",
    "            image,\r\n",
    "            (int(box[0]), int(box[1])),\r\n",
    "            (int(box[2]), int(box[3])),\r\n",
    "            color, 2\r\n",
    "        )\r\n",
    "        cv2.putText(image, classes[i], (int(box[0]), int(box[1]-5)),\r\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2, \r\n",
    "                    lineType=cv2.LINE_AA)\r\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the argument parser\r\n",
    "# parser = argparse.ArgumentParser()\r\n",
    "# parser.add_argument('-i', '--input', help='path to input image/video')\r\n",
    "# parser.add_argument('-m', '--min-size', dest='min_size', default=800, help='minimum input size for the FasterRCNN network')\r\n",
    "# args = vars(parser.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'input': '../V1/input/horses.jpg', 'min_size': 800}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download or load the model from disk\r\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True, min_size=args['min_size'])\r\n",
    "\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "\r\n",
    "image = Image.open(args['input'])\r\n",
    "model.eval().to(device)\r\n",
    "boxes, classes, labels = predict(image, model, device, 0.8)\r\n",
    "image = draw_boxes(boxes, classes, labels, image)\r\n",
    "# cv2.imshow('Image', image)\r\n",
    "save_name = f\"{args['input'].split('/')[-1].split('.')[0]}_{args['min_size']}\"\r\n",
    "cv2.imwrite(f\"outputs/{save_name}.jpg\", image)\r\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = fo.Dataset(\r\n",
    "#     \"../V1/datasets/coco/images/val2017\", \r\n",
    "#     dataset_type=fo.types.COCODetectionDataset, \r\n",
    "#     name=\"my_dataset\"\r\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dataset 'my-dataset5' already exists; use `fiftyone.load_dataset()` to load an existing dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-db6af7759ac6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdataset_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOCODetectionDataset\u001b[0m  \u001b[1;31m# for example\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fiftyone\\core\\dataset.py\u001b[0m in \u001b[0;36mfrom_dir\u001b[1;34m(cls, dataset_dir, dataset_type, data_path, labels_path, name, label_field, tags, **kwargs)\u001b[0m\n\u001b[0;32m   3377\u001b[0m             \u001b[0ma\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;32mclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3378\u001b[0m         \"\"\"\n\u001b[1;32m-> 3379\u001b[1;33m         \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3380\u001b[0m         dataset.add_dir(\n\u001b[0;32m   3381\u001b[0m             \u001b[0mdataset_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fiftyone\\core\\singletons.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, name, _create, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m         ):\n\u001b[0;32m     32\u001b[0m             \u001b[0minstance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_create\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_create\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m  \u001b[1;31m# `__init__` may have changed `name`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_instances\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fiftyone\\core\\dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, persistent, overwrite, _create, _migrate, _patches, _frames)\u001b[0m\n\u001b[0;32m    235\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sample_doc_cls\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_frame_doc_cls\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m             \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_create_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m                 \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpersistent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpersistent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_patches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_frames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\fiftyone\\core\\dataset.py\u001b[0m in \u001b[0;36m_create_dataset\u001b[1;34m(name, persistent, patches, frames)\u001b[0m\n\u001b[0;32m   4219\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_create_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpersistent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4220\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdataset_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4221\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   4222\u001b[0m             (\n\u001b[0;32m   4223\u001b[0m                 \u001b[1;34m\"Dataset '%s' already exists; use `fiftyone.load_dataset()` \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dataset 'my-dataset5' already exists; use `fiftyone.load_dataset()` to load an existing dataset"
     ]
    }
   ],
   "source": [
    "# A name for the dataset\r\n",
    "name = \"my-dataset5\"\r\n",
    "\r\n",
    "# The directory containing the dataset to import\r\n",
    "dataset_dir = \"../V1/datasets/coco/images/\"\r\n",
    "\r\n",
    "# The type of the dataset being imported\r\n",
    "# Any subclass of `fiftyone.types.Dataset` is supported\r\n",
    "dataset_type = fo.types.COCODetectionDataset  # for example\r\n",
    "\r\n",
    "dataset = fo.Dataset.from_dir(dataset_dir, dataset_type, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fo.load_dataset(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.utils.coco as fouc\r\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FiftyOneTorchDataset(torch.utils.data.Dataset):\r\n",
    "    \"\"\"A class to construct a PyTorch dataset from a FiftyOne dataset.\r\n",
    "    \r\n",
    "    Args:\r\n",
    "        fiftyone_dataset: a FiftyOne dataset or view that will be used for \r\n",
    "            training or testing\r\n",
    "        transforms (None): a list of PyTorch transforms to apply to images \r\n",
    "            and targets when loading\r\n",
    "        gt_field (\"ground_truth\"): the name of the field in fiftyone_dataset \r\n",
    "            that contains the desired labels to load\r\n",
    "        classes (None): a list of class strings that are used to define the \r\n",
    "            mapping between class names and indices. If None, it will use \r\n",
    "            all classes present in the given fiftyone_dataset.\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    def __init__(\r\n",
    "        self,\r\n",
    "        fiftyone_dataset,\r\n",
    "        transforms=None,\r\n",
    "        gt_field=\"ground_truth\",\r\n",
    "        classes=None,\r\n",
    "    ):\r\n",
    "        self.samples = fiftyone_dataset\r\n",
    "        self.transforms = transforms\r\n",
    "        self.gt_field = gt_field\r\n",
    "\r\n",
    "        self.img_paths = self.samples.values(\"filepath\")\r\n",
    "\r\n",
    "        self.classes = classes\r\n",
    "        if not self.classes:\r\n",
    "            # Get list of distinct labels that exist in the view\r\n",
    "            self.classes = self.samples.distinct(\r\n",
    "                \"%s.detections.label\" % gt_field\r\n",
    "            )\r\n",
    "\r\n",
    "        if self.classes[0] != \"background\":\r\n",
    "            self.classes = [\"background\"] + self.classes\r\n",
    "\r\n",
    "        self.labels_map_rev = {c: i for i, c in enumerate(self.classes)}\r\n",
    "\r\n",
    "    def __getitem__(self, idx):\r\n",
    "        img_path = self.img_paths[idx]\r\n",
    "        sample = self.samples[img_path]\r\n",
    "        metadata = sample.metadata\r\n",
    "        img = Image.open(img_path).convert(\"RGB\")\r\n",
    "\r\n",
    "        boxes = []\r\n",
    "        labels = []\r\n",
    "        area = []\r\n",
    "        iscrowd = []\r\n",
    "        detections = sample[self.gt_field].detections\r\n",
    "        for det in detections:\r\n",
    "            coco_obj = fouc.COCOObject.from_detection(\r\n",
    "                det, metadata, labels_map_rev=self.labels_map_rev\r\n",
    "            )\r\n",
    "            x, y, w, h = coco_obj.bbox\r\n",
    "            boxes.append([x, y, x + w, y + h])\r\n",
    "            labels.append(coco_obj.category_id)\r\n",
    "            area.append(coco_obj.area)\r\n",
    "            iscrowd.append(coco_obj.iscrowd)\r\n",
    "\r\n",
    "        target = {}\r\n",
    "        target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\r\n",
    "        target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\r\n",
    "        target[\"image_id\"] = torch.as_tensor([idx])\r\n",
    "        target[\"area\"] = torch.as_tensor(area, dtype=torch.float32)\r\n",
    "        target[\"iscrowd\"] = torch.as_tensor(iscrowd, dtype=torch.int64)\r\n",
    "\r\n",
    "        if self.transforms is not None:\r\n",
    "            img, target = self.transforms(img, target)\r\n",
    "\r\n",
    "        return img, target\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.img_paths)\r\n",
    "\r\n",
    "    def get_classes(self):\r\n",
    "        return self.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.FiftyOneTorchDataset at 0x23580999ca0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = FiftyOneTorchDataset(dataset)\r\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, y in dataloader:\r\n",
    "#     print(x)\r\n",
    "#     print (y)    \r\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}