{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CarvanaSetupColab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0eLWfmjjx_-"
      },
      "source": [
        "# !unzip train_images.zip -d data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JiGhmpAl0wb"
      },
      "source": [
        "# !unzip train_masks.zip -d data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUceEWGovhAe"
      },
      "source": [
        "# !unzip val_images.zip -d data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieyuJgBjvemJ"
      },
      "source": [
        "# !unzip val_masks.zip -d data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG3k1oTSmOkZ"
      },
      "source": [
        "# !rm -rf data/train_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lmwuf1YvOdB"
      },
      "source": [
        "# !rm -rf data/train_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce5_hrZlw3cf"
      },
      "source": [
        "# !ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xh3f_00pw4Cq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aac961b-f154-4308-c09d-7489e0876915"
      },
      "source": [
        "!python train.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> Loading checkpoint\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "Got 3653761/3686400 with acc 99.11\n",
            "Dice score: 0.9790122509002686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNuCBrmNw90C"
      },
      "source": [
        "# !pip install albumentations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujmqw7r-wKCk"
      },
      "source": [
        "# !pip uninstall albumentations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c2sefMNzvHP"
      },
      "source": [
        "# !pip install albumentations==0.4.6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRULsbdH_cO4"
      },
      "source": [
        "# mkdir adv_dir\n",
        "# mkdir target_adv_maskdir\n",
        "# mkdir saved_images\n",
        "# mkdir adv_maskdir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP-7bZP7OBpN"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from model import UNET\n",
        "from utils import (\n",
        "    load_checkpoint,\n",
        "    save_checkpoint,\n",
        "    get_loaders,\n",
        "    check_accuracy,\n",
        "    save_predictions_as_imgs,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHPJv6_4DTUg"
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "from dataset import CarvanaDataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SooRFK-3Zwvc"
      },
      "source": [
        "import albumentations as A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZiO5TP4ZzoJ"
      },
      "source": [
        "from albumentations.pytorch import ToTensorV2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xo_HI3rHa7es"
      },
      "source": [
        "from model import DoubleConv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PASaq2_zahnI"
      },
      "source": [
        "from dataset import CarvanaDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHDe80JaZi92"
      },
      "source": [
        "# Hyperparameters etc.\n",
        "LEARNING_RATE = 1e-4\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 1\n",
        "NUM_EPOCHS = 0\n",
        "NUM_WORKERS = 2\n",
        "IMAGE_HEIGHT = 160  # 1280 originally\n",
        "IMAGE_WIDTH = 240  # 1918 originally\n",
        "PIN_MEMORY = True\n",
        "LOAD_MODEL = False\n",
        "TRAIN_IMG_DIR = \"data/train_images/\"\n",
        "TRAIN_MASK_DIR = \"data/train_masks/\"\n",
        "VAL_IMG_DIR = \"data/val_images/\"\n",
        "VAL_MASK_DIR = \"data/val_masks/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB6Zuq5XaAAW",
        "outputId": "1e9a90c5-370a-4ded-bf83-3da3006f3be2"
      },
      "source": [
        "pretrained_model = \"my_checkpoint.pth.tar\"\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT_Ex2GZaMMT",
        "outputId": "b147b2e1-7c32-4347-f90e-55c97094d1c4"
      },
      "source": [
        "model = UNET().to(device)\n",
        "# model.load_state_dict(torch.load(pretrained_model))\n",
        "load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model)\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> Loading checkpoint\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UNET(\n",
              "  (ups): ModuleList(\n",
              "    (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (1): DoubleConv(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (2): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (3): DoubleConv(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (4): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (5): DoubleConv(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (6): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (7): DoubleConv(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (downs): ModuleList(\n",
              "    (0): DoubleConv(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (1): DoubleConv(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (2): DoubleConv(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (3): DoubleConv(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (bottleneck): DoubleConv(\n",
              "    (conv): Sequential(\n",
              "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (final_conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0fX7FhrZtQ8"
      },
      "source": [
        "train_transform = A.Compose(\n",
        "        [\n",
        "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "            A.Rotate(limit=35, p=1.0),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.VerticalFlip(p=0.1),\n",
        "            A.Normalize(\n",
        "                mean=[0.0, 0.0, 0.0],\n",
        "                std=[1.0, 1.0, 1.0],\n",
        "                max_pixel_value=255.0,\n",
        "            ),\n",
        "            ToTensorV2(),\n",
        "        ],\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM4OzW7DZ3eZ"
      },
      "source": [
        "val_transforms = A.Compose(\n",
        "        [\n",
        "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "            A.Normalize(\n",
        "                mean=[0.0, 0.0, 0.0],\n",
        "                std=[1.0, 1.0, 1.0],\n",
        "                max_pixel_value=255.0,\n",
        "            ),\n",
        "            ToTensorV2(),\n",
        "        ],\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7SqqckEZZss"
      },
      "source": [
        "train_loader, val_loader = get_loaders(\n",
        "        TRAIN_IMG_DIR,\n",
        "        TRAIN_MASK_DIR,\n",
        "        VAL_IMG_DIR,\n",
        "        VAL_MASK_DIR,\n",
        "        BATCH_SIZE,\n",
        "        train_transform,\n",
        "        val_transforms,\n",
        "        NUM_WORKERS,\n",
        "        PIN_MEMORY,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXX7MJxFZk4z",
        "outputId": "91f94224-480d-44d7-892b-98497b1bcc64"
      },
      "source": [
        "for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "    print(batch_idx)\n",
        "    print(data.size())\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "torch.Size([1, 3, 160, 240])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0_qHEDxXIeD"
      },
      "source": [
        "import string\n",
        "import random\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLHSfS_0fsqD"
      },
      "source": [
        "def test(model, device, dl, epsilon):\n",
        "  adversarial_images = []\n",
        "  correct = 0\n",
        "  loss_fn = nn.BCEWithLogitsLoss()\n",
        "  name = string.ascii_lowercase\n",
        "\n",
        "  for batch_idx, (data, targets) in enumerate(dl):\n",
        "    name = ''.join(random.choice(name) for i in range(10))\n",
        "\n",
        "    data = data.to(device)\n",
        "\n",
        "    targets = targets.float().unsqueeze(1).to(device=DEVICE)\n",
        "    \n",
        "    data.requires_grad = True\n",
        "\n",
        "    output = model(data)\n",
        "    \n",
        "    for i in range(5):\n",
        "      \n",
        "      loss = loss_fn(output, targets)\n",
        "\n",
        "      model.zero_grad()\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      data_grad = data.grad.data.sign()\n",
        "\n",
        "      perturbed_image = data + epsilon*data_grad\n",
        "\n",
        "      data = perturbed_image.clone().detach()\n",
        "\n",
        "      data.requires_grad_()\n",
        "\n",
        "      output = model(data)\n",
        "\n",
        "      adv_mask = model(perturbed_image)\n",
        "\n",
        "    #Saving Adv Image and Corresponding Target Mask for Accuracy\n",
        "    torchvision.utils.save_image(data, f\"adv_dir/{batch_idx}{name}.jpg\")\n",
        "    time.sleep(.001)\n",
        "    torchvision.utils.save_image(targets, f\"target_adv_maskdir/{batch_idx}{name}_mask.gif\")\n",
        "    time.sleep(.001)\n",
        "\n",
        "\n",
        "    # Saving Adv Masks for Fun\n",
        "    torchvision.utils.save_image(adv_mask, f\"adv_maskdir/{batch_idx}{name}_advmask.jpg\")\n",
        "    time.sleep(.001)\n",
        "\n",
        "    # if batch_idx == 3:\n",
        "    #   break\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsxXE4oMlflD"
      },
      "source": [
        "epsilon = .09\n",
        "# for i in range(10):\n",
        "test(model, device, val_loader, epsilon)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iyFMIdMGhUy",
        "outputId": "f944803d-8325-48c8-a9f1-f97d5e13a4d7"
      },
      "source": [
        "print(len(val_loader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0kSDOjBfGHT"
      },
      "source": [
        "ADV_DIR = \"adv_dir/\"\n",
        "ADV_MASK_DIR = \"adv_maskdir/\"\n",
        "TARGET_ADV_MASKDIR = \"target_adv_maskdir/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4cStNI0phHx"
      },
      "source": [
        "def get_adv_loader(\n",
        "    adv_dir,\n",
        "    adv_maskdir,\n",
        "    batch_size,\n",
        "    train_transform,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "):\n",
        "    adv_ds = CarvanaDataset(\n",
        "        image_dir=adv_dir,\n",
        "        mask_dir=adv_maskdir,\n",
        "        transform=train_transform,\n",
        "    )\n",
        "\n",
        "    adv_loader = DataLoader(\n",
        "        adv_ds,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=pin_memory,\n",
        "        shuffle=False,\n",
        "    )\n",
        "\n",
        "    return adv_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2OFokRVZ0JQ",
        "outputId": "624defdc-8187-4374-fdfb-85079051eac8"
      },
      "source": [
        "# !rm adv_dir/.ipynb_checkpoints\n",
        "adv_loader = get_adv_loader(\n",
        "        ADV_DIR, \n",
        "        TARGET_ADV_MASKDIR, \n",
        "        BATCH_SIZE,\n",
        "        val_transforms,\n",
        "        NUM_WORKERS,\n",
        "        PIN_MEMORY, )\n",
        "# adv_loader\n",
        "\n",
        "#CHECK ACCURACRY HERE\n",
        "check_accuracy(adv_loader, model, device=DEVICE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Got 2812665/3686400 with acc 76.30\n",
            "Dice score: 0.2321237027645111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTEDdOZKk-LL"
      },
      "source": [
        "# rmdir adv_dir/.ipynb_checkpoints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2vt9BkM_NMy"
      },
      "source": [
        "!rm -rf adv_dir\n",
        "!rm -rf target_adv_maskdir\n",
        "!rm -rf adv_maskdir\n",
        "\n",
        "!mkdir adv_dir\n",
        "!mkdir target_adv_maskdir\n",
        "!mkdir adv_maskdir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JLA4RI_BTqS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}